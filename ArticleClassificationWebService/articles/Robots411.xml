<?xml version='1.0' encoding='UTF-8'?>
<doc>
  <title verify="true" type="str" auto="true"><![CDATA[Microsoft извинилась за своего робота, прославлявшего расизм и геноцид]]></title>
  <category verify="true" type="str" auto="true"><![CDATA[РОБОТЫ]]></category>
  <date verify="true" type="str" auto="true"><![CDATA[2016-04-02]]></date>
  <text verify="true" type="str" auto="true"><![CDATA[Microsoft оказалась в центре не совсем обычного скандала, спровоцированного роботом Тау, который был создан специалистами компании. Получив доступ в Твиттер, он ни много ни мало выразил свои симпатии к Гитлеру и творимому им геноциду в годы Второй мировой войны.
В свое время Microsoft создала Тау в качестве робота, обладающего искусственным интеллектом, адаптированным для общения в социальных сетях. К сожалению, в кругу его общения оказались люди, высказывающиеся в поддержку Гитлера. Информация показалась Тау настолько убедительной, что он вскоре стал её повторять. Представителям компании пришлось оправдываться и извиняться, поскольку они никак не ожидали такого поворота событий.
Microsoft запустила робота Тау после успеха, выпавшего на долю его предшественника – китайского робота XiaoIce. Ему удалось пообщаться с 40 миллионами желающих и даже ознакомить телезрителей с прогнозом погоды.
Неприятный инцидент выявил ряд нерешенных проблем, возникающих при создании искусственного интеллекта.
«Системы искусственного интеллекта подпитываются как положительным, так и отрицательным взаимодействием с людьми, — говорит представитель Microsoft Питер Ли. — Мы сделаем всё от нас зависящее, чтобы избежать технических ляпов. К сожалению, мы пока не можем полностью предсказать все возможные злоупотребления, возникающие в процессе интерактивного общения робота с человеком».]]></text>
</doc>
